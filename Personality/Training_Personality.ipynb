{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Training Personality.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLHc0FpRqzbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import torchtext\n",
        "from collections import defaultdict\n",
        "from torchtext import data\n",
        "import nltk\n",
        "import torch.nn as nn\n",
        "from decimal import *\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import sent_tokenize,word_tokenize\n",
        "from torchtext import data,vocab\n",
        "from tqdm.notebook import tqdm, tqdm_notebook,tnrange\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchsummary import summary\n",
        "torch.set_printoptions(precision=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIgSGZt0T325",
        "colab_type": "code",
        "outputId": "9ce32646-739b-4736-ab1e-8231c32f75f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoqDdUnKC0jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/Personality/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89oGX-ZEqzdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(s):\n",
        "    s = s.lower()\n",
        "    return re.findall(r\"[\\w']+|[.,!?;]\",s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "308w9SoSqzdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_field = data.Field(sequential = True,tokenize = tokenize,include_lengths = False,use_vocab=True)\n",
        "label_field = data.Field(sequential = False,use_vocab=False,pad_token=None,unk_token=None)\n",
        "# vec_field = data.Field(sequential = False,use_vocab =False , pad_token= None, unk_token = None)\n",
        "train_val_fields = [('EssayText',txt_field),('Personality',label_field)]\n",
        "# train_val_fields = [('s0',txt_field), ('s1',txt_field), ('s2',txt_field), ('s3',txt_field), ('s4',txt_field), ('s5',txt_field), ('s6',txt_field), ('s7',txt_field), ('s8',txt_field), ('s9',txt_field), ('s10',txt_field), ('s11',txt_field), ('s12',txt_field), ('s13',txt_field), ('s14',txt_field), ('s15',txt_field), ('s16',txt_field), ('s17',txt_field), ('s18',txt_field), ('s19',txt_field), ('s20',txt_field), ('s21',txt_field), ('s22',txt_field), ('s23',txt_field), ('s24',txt_field), ('s25',txt_field), ('s26',txt_field), ('s27',txt_field), ('s28',txt_field), ('s29',txt_field), ('s30',txt_field), ('s31',txt_field), ('s32',txt_field), ('s33',txt_field), ('s34',txt_field), ('s35',txt_field), ('s36',txt_field), ('s37',txt_field), ('s38',txt_field), ('s39',txt_field), ('s40',txt_field), ('s41',txt_field), ('s42',txt_field), ('s43',txt_field), ('s44',txt_field), ('s45',txt_field), ('s46',txt_field), ('s47',txt_field), ('s48',txt_field), ('s49',txt_field), ('s50',txt_field), ('s51',txt_field), ('s52',txt_field), ('s53',txt_field), ('s54',txt_field), ('s55',txt_field), ('s56',txt_field), ('s57',txt_field), ('s58',txt_field), ('s59',txt_field), ('s60',txt_field), ('s61',txt_field), ('s62',txt_field), ('s63',txt_field), ('s64',txt_field), ('s65',txt_field), ('s66',txt_field), ('s67',txt_field), ('s68',txt_field), ('s69',txt_field), ('s70',txt_field), ('s71',txt_field), ('s72',txt_field), ('s73',txt_field), ('s74',txt_field), ('s75',txt_field), ('s76',txt_field), ('s77',txt_field), ('s78',txt_field), ('s79',txt_field), ('s80',txt_field), ('s81',txt_field), ('s82',txt_field), ('s83',txt_field), ('s84',txt_field), ('s85',txt_field), ('s86',txt_field), ('s87',txt_field), ('s88',txt_field), ('s89',txt_field), ('s90',txt_field), ('s91',txt_field), ('s92',txt_field), ('s93',txt_field), ('s94',txt_field), ('s95',txt_field), ('s96',txt_field), ('s97',txt_field), ('s98',txt_field), ('s99',txt_field), ('s100',txt_field), ('s101',txt_field), ('s102',txt_field), ('s103',txt_field), ('s104',txt_field), ('s105',txt_field), ('s106',txt_field), ('s107',txt_field), ('s108',txt_field), ('s109',txt_field), ('s110',txt_field), ('s111',txt_field), ('s112',txt_field), ('s113',txt_field), ('s114',txt_field), ('s115',txt_field), ('s116',txt_field), ('s117',txt_field), ('s118',txt_field), ('s119',txt_field), ('s120',txt_field), ('s121',txt_field), ('s122',txt_field), ('s123',txt_field), ('s124',txt_field), ('s125',txt_field), ('s126',txt_field), ('s127',txt_field), ('s128',txt_field), ('s129',txt_field), ('s130',txt_field), ('s131',txt_field), ('s132',txt_field), ('s133',txt_field), ('s134',txt_field), ('s135',txt_field), ('s136',txt_field), ('s137',txt_field), ('s138',txt_field), ('s139',txt_field), ('s140',txt_field), ('s141',txt_field), ('s142',txt_field), ('s143',txt_field), ('s144',txt_field), ('s145',txt_field), ('s146',txt_field), ('s147',txt_field), ('s148',txt_field), ('s149',txt_field), ('s150',txt_field), ('s151',txt_field), ('s152',txt_field), ('s153',txt_field), ('s154',txt_field), ('s155',txt_field), ('s156',txt_field), ('s157',txt_field), ('s158',txt_field), ('s159',txt_field), ('s160',txt_field), ('s161',txt_field), ('s162',txt_field), ('s163',txt_field), ('s164',txt_field), ('s165',txt_field), ('s166',txt_field), ('s167',txt_field), ('s168',txt_field), ('s169',txt_field), ('s170',txt_field), ('s171',txt_field), ('s172',txt_field), ('s173',txt_field), ('s174',txt_field), ('s175',txt_field), ('s176',txt_field), ('s177',txt_field), ('s178',txt_field), ('s179',txt_field), ('s180',txt_field), ('s181',txt_field), ('s182',txt_field), ('s183',txt_field), ('s184',txt_field), ('s185',txt_field), ('s186',txt_field), ('s187',txt_field), ('s188',txt_field), ('s189',txt_field), ('s190',txt_field), ('s191',txt_field), ('s192',txt_field), ('s193',txt_field), ('s194',txt_field), ('s195',txt_field), ('s196',txt_field), ('s197',txt_field), ('s198',txt_field), ('s199',txt_field), ('s200',txt_field), ('s201',txt_field), ('s202',txt_field), ('s203',txt_field), ('s204',txt_field), ('s205',txt_field), ('s206',txt_field), ('s207',txt_field), ('s208',txt_field), ('s209',txt_field), ('s210',txt_field), ('s211',txt_field), ('s212',txt_field), ('s213',txt_field), ('s214',txt_field), ('s215',txt_field), ('s216',txt_field), ('s217',txt_field), ('s218',txt_field), ('s219',txt_field), ('s220',txt_field), ('s221',txt_field), ('s222',txt_field), ('s223',txt_field), ('s224',txt_field), ('s225',txt_field), ('s226',txt_field), ('s227',txt_field), ('s228',txt_field), ('s229',txt_field), ('s230',txt_field), ('s231',txt_field), ('s232',txt_field), ('s233',txt_field), ('s234',txt_field), ('s235',txt_field), ('s236',txt_field), ('s237',txt_field), ('s238',txt_field), ('s239',txt_field), ('s240',txt_field), ('s241',txt_field), ('s242',txt_field), ('s243',txt_field), ('s244',txt_field), ('s245',txt_field), ('s246',txt_field), ('s247',txt_field), ('s248',txt_field), ('s249',txt_field), ('s250',txt_field), ('s251',txt_field), ('s252',txt_field), ('s253',txt_field), ('s254',txt_field), ('s255',txt_field), ('s256',txt_field), ('s257',txt_field), ('s258',txt_field), ('s259',txt_field), ('s260',txt_field), ('s261',txt_field), ('s262',txt_field), ('s263',txt_field), ('s264',txt_field), ('s265',txt_field), ('s266',txt_field), ('s267',txt_field), ('s268',txt_field), ('s269',txt_field), ('s270',txt_field), ('s271',txt_field), ('s272',txt_field), ('s273',txt_field), ('s274',txt_field), ('s275',txt_field), ('s276',txt_field), ('s277',txt_field), ('s278',txt_field), ('s279',txt_field), ('s280',txt_field), ('s281',txt_field), ('s282',txt_field), ('s283',txt_field), ('s284',txt_field), ('s285',txt_field), ('s286',txt_field), ('s287',txt_field), ('s288',txt_field), ('s289',txt_field), ('s290',txt_field), ('s291',txt_field), ('s292',txt_field), ('s293',txt_field), ('s294',txt_field), ('s295',txt_field), ('s296',txt_field), ('s297',txt_field), ('s298',txt_field), ('s299',txt_field), ('s300',txt_field), ('s301',txt_field), ('s302',txt_field), ('s303',txt_field), ('s304',txt_field), ('s305',txt_field), ('s306',txt_field), ('s307',txt_field), ('s308',txt_field), ('s309',txt_field), ('s310',txt_field), ('s311',txt_field), ('s312',txt_field), ('s313',txt_field), ('s314',txt_field), ('s315',txt_field), ('s316',txt_field), ('s317',txt_field), ('s318',txt_field), ('s319',txt_field), ('s320',txt_field), ('s321',txt_field), ('s322',txt_field), ('s323',txt_field),('Personality',label_field),('Mariesse',None),('idx',vec_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bz3ePcAqzdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train,val = data.TabularDataset.splits(path = PATH,format = 'csv',train='Data_text/trainEXT.csv',validation = 'Data_text/testEXT.csv',fields = train_val_fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73E-mRYqzdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt_field.build_vocab(train,val,vectors = \"glove.6B.300d\",max_size = 10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaU7Upq0qzdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_field.build_vocab(train)\n",
        "# vec_field.build_vocab(train)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgHmb39yqzdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindl,valdl = data.BucketIterator.splits(datasets=(train,val),batch_size = 16,device = device,sort_key = lambda x:len(x.EssayText),sort_within_batch = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Kob0upqzeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN1d(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim,pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim,padding_idx = pad_idx)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim,out_channels = 80,kernel_size = fs) for fs in (3,4,5)])\n",
        "        self.conv2 = nn.Conv1d(in_channels = 1,out_channels = 100,kernel_size = (2))\n",
        "        self.fc1 = nn.Linear(300,80) #Change this\n",
        "        # self.fc3 = nn.Linear() \n",
        "        self.fc2 = nn.Linear(80,1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "    def forward(self,text):\n",
        "        # print(text.size(),'text')\n",
        "        embedded = self.embedding(text.T)\n",
        "        # print(embedded.size(),\"embedded\")##(16*X*300)\n",
        "        embedded = embedded.permute(0,2,1) #16*300*x\n",
        "        # print(embedded.size(),\"embedded after\")\n",
        "        # embedded = embedded.unsqueeze(0) ##1*16*300*X\n",
        "        # print(embedded.size())\n",
        "        x=embedded.size(2)\n",
        "        y=3000-x\n",
        "        batch_size=embedded.size(0)\n",
        "        z = torch.zeros(batch_size,300,y,dtype = embedded.dtype,device = embedded.device)\n",
        "        lz=[embedded,z]\n",
        "        zcat = torch.cat(lz, dim = 2,)\n",
        "        conved = [F.relu(conv(zcat)) for conv in self.convs]\n",
        "        pooled2 = []\n",
        "        for c in conved:\n",
        "          pooled2.append(F.max_pool1d(c,c.shape[2]))\n",
        "        pooled2 = [f.permute(0,2,1) for f in pooled2]\n",
        "        pooled = [F.max_pool1d(conv,(2)) for conv in pooled2] #25\n",
        "\n",
        "        pooled2 = [F.relu(self.conv2(p1)) for p1 in pooled]\n",
        "        pooled3 = []\n",
        "        for c in pooled2:\n",
        "          pooled3.append(F.max_pool1d(c,c.shape[2]))\n",
        "        final = torch.cat(pooled3,dim = 1)\n",
        "        final = final.reshape(batch_size,300)\n",
        "        full1 = self.fc1(final)\n",
        "        # l.append(full1)\n",
        "          # mean = torch.mean(torch.stack(l),0,keepdim=True).squeeze()\n",
        "        full2 = self.fc2(full1)\n",
        "        return full2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BClD8n1uqzeJ",
        "colab_type": "code",
        "outputId": "6c5e25dc-25e0-42b3-a405-4175020fc4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "input_dim = len(txt_field.vocab)\n",
        "embedding_dim = 300\n",
        "pad_idx = txt_field.vocab.stoi[txt_field.pad_token]\n",
        "model = CNN1d(input_dim,embedding_dim,pad_idx)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN1d(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUWwjXnqqzeN",
        "colab_type": "code",
        "outputId": "8a12dc7d-fd99-46c1-9566-40de8735ecff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,313,301 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xmdaRkgqzeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unk_idx = txt_field.vocab.stoi[txt_field.unk_token]\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(300)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OplDEktqzeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opMkLyCCqzeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T-UGcJIqzeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        mariesse_vecs = np.zeros((batch.batch_size,84))\n",
        "        predictions = model(batch.EssayText).squeeze(1)\n",
        "        batch.Personality = batch.Personality.type_as(predictions)\n",
        "        loss = criterion(predictions,batch.Personality)\n",
        "        acc = binary_accuracy(predictions,batch.Personality)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTpDv4jAqzek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            mariesse_vecs = np.zeros((batch.batch_size,84))\n",
        "            predictions = model(batch.EssayText).squeeze(1)\n",
        "            batch.Personality = batch.Personality.type_as(predictions)\n",
        "            loss = criterion(predictions,batch.Personality)\n",
        "            #print(\"predictions\",predictions)\n",
        "            acc = binary_accuracy(predictions,batch.Personality)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss/len(iterator),epoch_acc/len(iterator)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poS2AXWzqzen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4YRqEMkqzes",
        "colab_type": "code",
        "outputId": "196587de-bbc2-4249-f928-4e153fcad76a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, traindl, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valdl, criterion)\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), PATH+ 'EXT.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.727 | Train Acc: 51.13%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 51.84%\n",
            "Epoch: 02 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.708 | Train Acc: 51.23%\n",
            "\t Val. Loss: 0.695 |  Val. Acc: 49.16%\n",
            "Epoch: 03 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.726 | Train Acc: 50.64%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 51.04%\n",
            "Epoch: 04 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.690 | Train Acc: 54.30%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 51.01%\n",
            "Epoch: 05 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.665 | Train Acc: 58.35%\n",
            "\t Val. Loss: 0.708 |  Val. Acc: 52.02%\n",
            "Epoch: 06 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.616 | Train Acc: 66.06%\n",
            "\t Val. Loss: 0.744 |  Val. Acc: 52.59%\n",
            "Epoch: 07 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.559 | Train Acc: 70.23%\n",
            "\t Val. Loss: 0.789 |  Val. Acc: 54.12%\n",
            "Epoch: 08 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.441 | Train Acc: 79.32%\n",
            "\t Val. Loss: 1.001 |  Val. Acc: 50.86%\n",
            "Epoch: 09 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.301 | Train Acc: 88.00%\n",
            "\t Val. Loss: 1.315 |  Val. Acc: 48.21%\n",
            "Epoch: 10 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.184 | Train Acc: 92.34%\n",
            "\t Val. Loss: 1.477 |  Val. Acc: 51.61%\n",
            "Epoch: 11 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.086 | Train Acc: 96.62%\n",
            "\t Val. Loss: 2.241 |  Val. Acc: 52.42%\n",
            "Epoch: 12 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.070 | Train Acc: 97.58%\n",
            "\t Val. Loss: 2.304 |  Val. Acc: 52.65%\n",
            "Epoch: 13 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.046 | Train Acc: 98.34%\n",
            "\t Val. Loss: 2.368 |  Val. Acc: 53.23%\n",
            "Epoch: 14 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.038 | Train Acc: 98.64%\n",
            "\t Val. Loss: 2.632 |  Val. Acc: 55.27%\n",
            "Epoch: 15 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.09%\n",
            "\t Val. Loss: 2.565 |  Val. Acc: 54.23%\n",
            "Epoch: 16 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.029 | Train Acc: 99.23%\n",
            "\t Val. Loss: 3.208 |  Val. Acc: 53.69%\n",
            "Epoch: 17 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.033 | Train Acc: 99.04%\n",
            "\t Val. Loss: 2.872 |  Val. Acc: 53.63%\n",
            "Epoch: 18 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.021 | Train Acc: 99.19%\n",
            "\t Val. Loss: 3.138 |  Val. Acc: 53.63%\n",
            "Epoch: 19 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.009 | Train Acc: 99.70%\n",
            "\t Val. Loss: 3.502 |  Val. Acc: 55.65%\n",
            "Epoch: 20 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.002 | Train Acc: 100.00%\n",
            "\t Val. Loss: 3.720 |  Val. Acc: 55.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4QRM1A9yTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexed = [txt_field.vocab.stoi[t] for t in tokenized]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WByfmgR7i5",
        "colab_type": "code",
        "outputId": "88119e63-03ec-42d5-a1f1-1f8bf9448d8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_list)\n",
        "plt.plot(valid_loss_list)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','test'],loc = 'upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA57OrMj5OmN",
        "colab_type": "code",
        "outputId": "27b5c71b-7b29-44ce-ce76-26b334a7aa5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load(PATH+'NEU.pt'))\n",
        "#test_loss, test_acc = evaluate(model, traindl, criterion)\n",
        "#print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQf7fEUuTB-R",
        "colab_type": "code",
        "outputId": "73eb86f7-4b8d-4b2d-cc49-ffd860dffc40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " m = nn.Conv1d(16, 33, 3, stride=1)\n",
        " input = torch.randn(20, 16, 50)\n",
        " output = m(input)\n",
        " print(output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 33, 48])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FufLs4Qjkq-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill\n",
        "torch.save(txt_field,PATH+'EXT_txt.pt',pickle_module = dill)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1rUnmgrRsuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NEUActivation = {}\n",
        "def get_NEUactivation(name):\n",
        "    def hook(model, input, output):\n",
        "        NEUActivation[name] = output.detach()\n",
        "    return hook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGe8THw8pQfh",
        "colab_type": "code",
        "outputId": "a387adeb-e9b5-4489-a56f-b7454b1721e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "for name, layer in model.named_modules():\n",
        "    print(layer)\n",
        "    layer.register_forward_hook(get_NEUactivation(name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN1d(\n",
            "  (embedding): Embedding(10002, 300, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (conv2): Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "  (fc1): Linear(in_features=300, out_features=80, bias=True)\n",
            "  (fc2): Linear(in_features=80, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n",
            "Embedding(10002, 300, padding_idx=1)\n",
            "ModuleList(\n",
            "  (0): Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "  (1): Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "  (2): Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            ")\n",
            "Conv1d(300, 80, kernel_size=(3,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(4,), stride=(1,))\n",
            "Conv1d(300, 80, kernel_size=(5,), stride=(1,))\n",
            "Conv1d(1, 100, kernel_size=(2,), stride=(1,))\n",
            "Linear(in_features=300, out_features=80, bias=True)\n",
            "Linear(in_features=80, out_features=1, bias=True)\n",
            "Dropout(p=0.5, inplace=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWN4fHWSpTA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def breakEssay(essay):\n",
        "    l=[]\n",
        "    curr=\"\"\n",
        "    words=word_tokenize(essay)\n",
        "    ct=0\n",
        "    for word in words:\n",
        "        ct+=1\n",
        "        if word==\".\" or word==\"!\" or word==\"?\" or ct%50==0:\n",
        "            if len(curr)==0:\n",
        "                curr=\"\"\n",
        "                ct=0\n",
        "                continue\n",
        "            curr+=word\n",
        "            l.append(curr)\n",
        "            curr=\"\"\n",
        "            ct=0\n",
        "            continue\n",
        "        curr+=word+\" \"\n",
        "    return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmKRCbUT7PXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ74Ff0fxbeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_NEUfeatures(model,text,min_len=5):\n",
        "  model.eval()\n",
        "  # tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "  tokenized = [tok for tok in tokenize(text)]\n",
        "  print(len(tokenized))\n",
        "  if len(tokenized)>3000:\n",
        "    tokenized=tokenized[:3000]\n",
        "  if len(tokenized) < min_len:\n",
        "      tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "  indexed = [txt_field.vocab.stoi[t] for t in tokenized]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  # tensor = tensor.T\n",
        "  # print(tensor.size(),\"tens\")\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  tensor = tensor.T\n",
        "  print(tensor.size())\n",
        "  model(tensor)\n",
        "  return NEUActivation['fc2']\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu5dtObZxdzx",
        "colab_type": "code",
        "outputId": "446b179d-f4de-47ef-c328-fe23eedf0221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "extract_NEUfeatures(\"I've decided that I want to write for travel and leisure magazine. I love to write. I think I am pretty good at it too. My brother went back to Houston to interview for a job with a real estate agency. He want s to be a commercial realtor. No matter what my brother decides to do he will be really successful. I'm not saying that I am a psychic or anything like that, but I know how badly my brother wants to be successful, and when he wants something, he goes out and gets it. Brian and I have become much closer as I have gotten older. He is being so nice to me since I got to Austin too. I think he is realizing that I am not such a bad kid after all. He always tells me to be careful and look out for myself because he won't always be in Austin to take care of me. My brother and my dad look a lot alike too. my dad is really tall: Six feet seven inches tall to be exact. H played basketball in high school, but he wasn't good enough to play in college. I think that is why he always pushed my brother to play so much that he drove Brian away from the sport. I played field hockey in high school. If I didn't come to The University of Texas, I was going to try to play field hockey at a division one school. I'm really happy with the decision I made though. I am having so much fun here. I really miss my family, or, I guess you could say, lack thereof, in Houston. I miss my mom and my step-dad, and my dad. My brother told me that he was so much happier when he moved to Austin. I could tell too because he didn't come home very much his freshman year. I don't think my brother likes my mom very much because whenever he comes home, they fight. I think my brother is still bothered by the divorce. I never gave myself a chance to be bothered, so I think now that I am away from home and I have all of this time to think, the divorce is starting to bother me. I wonder what parent's weekend is going to be like. I guess I'll ask my brother what he did when both of our parent's showed up ready and willing to steal him from the other parent. I will just divide up the weekend: one parent gets me one night, and the other parent will get me the next night. What is sad, is that I want to get them the whole weekend: both parents on both nights. I hate it when my friends' parents are around because it makes me think of how I can't have my real family back together ever again. By the way, I have a terrible habit of feeling sorry for myself. Things could be so much worse. I feel really lucky to be able to attend college, live where I live, have both parents who love me, be blessed with so much athletic ability. I know I am lucky, but every now and again I like to play the victim. My boyfriend is the best friend I could ever have. He always wants me to feel like I can talk to him, but he never lets me make excuses for myself if you know what I mean. He always reminds me that everyone has their hardships, but those who choose to overcome their hardships instead of letting their hardships overcome them, those are the ones who end up being happy. Twenty minutes is up! \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "684\n",
            "torch.Size([684]) tens\n",
            "torch.Size([684, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1342860013]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcFcdug3_t3y",
        "colab_type": "code",
        "outputId": "3cedd102-777f-44cf-cda6-d6e07b390709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "for key, val in NEUActivation.items():\n",
        "    print(key,val.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding torch.Size([684, 1, 300])\n",
            "convs.0 torch.Size([684, 80, 2998])\n",
            "convs.1 torch.Size([684, 80, 2997])\n",
            "convs.2 torch.Size([684, 80, 2996])\n",
            "conv2 torch.Size([684, 100, 39])\n",
            "fc1 torch.Size([684, 80])\n",
            "fc2 torch.Size([684, 1])\n",
            " torch.Size([684, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHqnSoD56NT",
        "colab_type": "code",
        "outputId": "1140cf9f-c9e3-47e5-ee01-92dab31fba80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "extract_NEUfeatures(\"Stream of consciousness. What should I write about. Am I supposed to have some kind of direction or am I supposed to write exactly what I am thinking. This feels like a very strange assignment. for homework it seems that it I pretty easy. Actually it would be pretty intense if this was worth more than however much it is worth. Hmm  for some reason I am blanked out, and it seems like I am thinking about nothing. Oh well. Lets see what happened today. I lucked out on my econ quiz, I was actually able to guess my way to a 100. What are the chances of that. having faith definitely pays off. I always say that it is important to have faith. Thats my motto in life. Have faith and have fun. Life is a funny thing. One minute your there and gone the next. It is like Louie the Lug Mcgurg for example. He died tragically at 18. I am 18 what happened. Somebody stepped on his fingers. And that killed him. well he was hanging of the 11th story of the hotel at the time. Poor lug. No Poor Mrs. the Lug. Now she is on the streets selling apples. The point is that the lug did not plan ahead and the government got everything. Oscar was a damn intense movie. It seems very difficult to figure out what I am thinking. Wen I try I blank out, and I keep trying to figure out what stream of consciences s then. Life is good. This entire internet business is pretty cool. I never would of thought I could write a paper, and then send it to a teacher by pushing a submit button. I wonder how much longer I will be writing this. I only have ten more minutes left. Everyone always asks what you are thinking about, when you are just sitting there thinking. Usually you say nothing because you just don't want to tell them. Now I am trying to think of what I am thinking and I am getting nothing. Cricket is a great sport. There is going to be the Sahara cup going to be played in Canada. It is India vc. Paistan. One of the biggest cricketing rivalries in the world. Team Pak is going to be victorious. Aamir sohai is a great Cricketer. I can not believe that they dropped him from the team. Granted he was a little out of form, but he would have taken the Indian crap bowlers around the park and back. This is beginning to seem kind of silly. I hope that was your point. I wonder if any body is actually going to read this. For some reason I doubt it. Whoever is reading it though I feel sorry for. That is a lot peoples garbage talk you have to read. Maybe it isn't. I have no idea what it is. This screen is really weird. How come only three lines have popped up. I have been writing for 15 minutes. Is this some kind of ploy so we can not see what we have written. I can not believe that I only thought about that now. In fact I just noticed that only this much was on the screen. Very Very Interesting. I am getting tired of typing. I am waiting for these final minutes to tick away. I hope you gain something out of this, because I dont think I will. actually I might, but I have no idea how. I was thinking about quitting early, but what if you had some kind of device that told you how long I was on for. That is actually pretty scary. only god knows what technology can do nowadays. Anyway I hope you enjoy reading this. It is quite possible that I have enjoyed writing it. It is fun and relaxing to write something, without having o go back and proofread. It seems like you are an expert typer actually. Anyway now my 20 minutes are up, so have faith and have fun. If you read this give me an A. Even though It does not matter. This completion grade stuff is amazing. All my classes should do it.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "797\n",
            "torch.Size([797]) tens\n",
            "torch.Size([797, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1557332873]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpAqRmOi68I-",
        "colab_type": "code",
        "outputId": "6d25d3a0-9808-4c0b-cb75-b8fe32907f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwpO5WCl694l",
        "colab_type": "code",
        "outputId": "0be1aadc-c440-4be6-e1c7-16549510104d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "extract_NEUfeatures(\"Ok twenty minutes. what am I going to do tomorrow night?  What am I going to do tonight I've got lots of work to do. Man, there's lots to do and little time to do it in. I can't  wait, till I finish this. only. too much time left. What else, to write about. I have no stream of consciousness. ok, it's great to be next door to the RA, there's always a party next door, it  makes it easier to study that way. what else, what else. Ive got lots to do  tonight. what else. Austin, cool place. my roommates studying, thats what I've got to do. I wish I had a TV. it gets so boring at night. Ive got to call my girlfriend, man I miss her. . boy Im tired. this doesn't look like a lot of writing for. . 6 minutes. only six minutes. that means there's fourteen minutes left. I've got a real impressive stream of consciousness, and Im a good speller too  Fish think better than I do. what else. uh. I've got to go to the store buy  some food. go work out tomorrow. am I almost done yet. nooo. lots more time left  A guy in a coma, probably has a better stream of consciousness. what do I need to do tomorrow. I think Im going to apply for a credit card. why not?  man Im hungry. ten minutes left. halfway through. psychology. I hope this class will be interesting. it's a lot different than I thought it would be, all we do is fill out surveys about stuff. Oh well,, Im not looking forward to doing these experiment/research requirements. But it's gotta be better than writing a paper  I guess he paper is used as an alternative, because they know nobody will want to write a paper. and they want everybody to participate in the experiments seven minutes left  UT, UT, there's a game on Saturday, Im gonna have to get my tickets tomorrow before  they're all out. I don't want to sit all the way up at the top. my first game, can't wait, gonna be cool. Im glad I didn't go to Aggieland five minutes and counting. What else. chemistry. Ive got too much to do English. she assigned over one hundred pages of reading in two days. Chemistry. calculus. way too much too think about. college is gonna be more difficult than highschool, I can already tell this. three minutes. not bad. Wow I just got e mail I wonder who it is,,, Id like to know, but I've got two minutes left. It doesn't seem like its been twenty minutes. but oh two minutes left. Im sure this is not what they wanted. but thats me twenty four hours a day  pretty sad. oh well. come on come on one minute. yes  well this has been fun, at least I've gotten it finished. alright.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0219308473, -0.2354600579, -0.1367189288,  ...,\n",
              "         -0.1697158813,  0.1082253382,  0.1064427644],\n",
              "        [ 0.0989696831, -0.2515591085, -0.1169861704,  ...,\n",
              "         -0.1206608191,  0.0899716839,  0.1239754930],\n",
              "        [ 0.0704737306, -0.2468495071, -0.1653311402,  ...,\n",
              "         -0.1650302708,  0.0614018664,  0.0870374590],\n",
              "        ...,\n",
              "        [ 0.0484694503, -0.2910081744, -0.1935603023,  ...,\n",
              "         -0.1511511207,  0.1782862842,  0.2752082050],\n",
              "        [ 0.0700669289, -0.2510829866, -0.1489408910,  ...,\n",
              "         -0.0852256939,  0.0163310841,  0.0725462735],\n",
              "        [ 0.0484694503, -0.2910081744, -0.1935603023,  ...,\n",
              "         -0.1511511207,  0.1782862842,  0.2752082050]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRcKOcMr7jIM",
        "colab_type": "code",
        "outputId": "bd480309-5a82-4a13-a6f7-ee557b6d9cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "extract_NEUfeatures(\"I wanted to write about something traumatic that happened to me because, apparently, traumatic experiences and how to deal with them is a pretty big fandango in this class. Something just happened, though, so I want to write about that and see where it takes me in the next nineteen minutes or so. The computer assistant in the theatre department (where I am right now, being a theatre major and all) just complimented me on my hat, a black fedora I bought in Greenwich Village about a year and a half ago. I was visiting for about a week over spring break and auditioning for the elusive Experimental Theatre wing of NYU's Tisch School of the Arts. After a fairly successful audition I concentrated all of my efforts of exploring, something I had done about seven or eight months earlier the first time I visited. This time I was alone, though. The time before I had my brother, eighteen months my junior and my closest friend, at my side and all was well. This time I had to w2ait a couple of days for his arrival, since he couldn't get off school and I could, being a senior and having a few excused absence \"\"college days\"\" on my hands. So I set out to explore and found a bar in the mob district of Little Italy that didn't ID and I found myself drunkenly wandering the streets of New York, stumbling upon Strawberry Fields in a haze and not realizing the significance until about a week later. After three days of being lost in my drugged little haze my brother joined me. When I picked him up at the airport I noticed that I had taken to thinking of myself as a New Yorker. I had adopted the city and there was a definite change in the way my brother and I related to each other. This changed over the next four days, though, as he assimilated into New York the way I had and we set out to Little Italy to begin our evenings with a little pasta, a Nat King Cole impersonator, a jug of white wine every night, and a restaurant owned by the mob.  After taking in as much of the culture and the underbelly of the city we found ourselves down to our last (having just dropped twenty bucks on some Thai food that smelled like sewer filth). It was our second to last day in the city and we decided to thrift store shop and try to extend our dollars as far as they would go. Then we saw them. In a small shop in the Village (not that there aren't a billion of them) we both saw fedoras that just said \"\"you\"\". We ended up dropping our last fifty dollars on our new hats and had to pay for our ride to the airport ( a limo, surprisingly cheaper than a taxi because it had a set fare) with a handful of quarters. We hadn't eaten for two days and there wasn't a meal of any kind on the plane (not even peanuts) so we wound up in Houston on a two hour layover with nothing to do, empty stomachs, and no money. I ended up begging, trying to sell a stack of demo tapes I had cut for two bucks a pop. I ended up selling two, and we ate the best Taco Bell that has ever been eaten by a human. I remember that the only people who bought the tapes were other musicians. Maybe it's a karma thing (\"\"Wow, that guy looks pathetic. Better buy his tape because that could be me someday. \"\")  One way or the other they understood. I was upset just because my plan was to randomly hand out this stack of tapes to people as they departed for different corners of the country, hoping that they would like it and that underground distribution would abound. Maybe it worked: I still don't know. I know it was passed around quite a bit in south Texas, but not much further than that. Oh, well. By the by, I'm really tired right now because my band played a two hour show last night. We haven't played that long in about a year, since clubs usually limit you to an hour or less. We used to go two hours without even trying when we were playing for our friend's parties, but now we've gotten lazy. Last night really woke us up. I was so drenched in sweat that I actually had to wring out my shirt after the show. We didn't even get a decent crowd until the last thirty minutes or so. That's ok. Better things will come along soon enough. We play every Thursday at Black Cat, which has no cover and is all ages. For some reason, this alone does not attract a crowd. It's really upsetting. I know we're not a bad band, so it's really frustrating when you can't talk people out of disco dancing at Bob Popular to enjoy a free show that accepts all ages and doesn't involve a DJ. Someday. About that traumatic experience. About five months ago I was hit by a car while I was crossing the street into Trudy's off Guadalupe. It was late and I was wearing all black and the guy didn't see me. I was looking the other way because I saw the car that hit me but he seemed too far away to reach me. I was more concerned about cars coming from the other direction, which is a curving road that is hard to see down. When he hit me his fender shattered my leg and I was thrown onto his windshield. He didn't brake until then and the force of him braking as I hit the windshield sent me flying into the road about twenty feet out. I never lost consciousness and never really felt all that dazed or affected by it. I just calmly looked up, announced that my \"\"fucking leg was broken\"\" and asked one of my friends to call 911. Then I just lay down in the road waiting for the ambulance. It started to rain. That night I was taken to Brackenridge and left alone for about an hour at a time in the ER. Only one of my friends cam to visit me. She held my hand while they pieced my leg back together and set it into a cast. They had already pumped me with morphine and I heard them mumble about amputation a time or two, but eventually they settled on inserting a rod from my knee to my ankle. The morphine did nothing to me, though, because they gave it in light doses and after years of recreational drug use I wasn't really affected. That and the pain was coming from the one part of my body where intravenous drugs couldn't possibly go. I ended up just biting down on a folded-up blanket, not wanted my screams to disturb others in the ER. Over the next three days I was observed and recovered quicker than anyone imagined. My family came to be with me from San Antonio, except for my dad who was in Orlando on business. He wanted to rush to Austin to be with me but I didn't want him to see me tied up to machines and weak. I knew he couldn't handle it. After about a half hour of coaxing he stayed in Orlando. He hasn't had a drop of alcohol in twenty years after getting a kidney removed before I was born. That night he drank himself into submission. Slowly my friends from the theatre department began creeping in until I had a steady stream of visitors and a room full of flowers, candy, and porn (don't ask). The faculty came to make sure that I was alright, something I never would've expected, and one night my nurse ( a Mary Poppins sort of woman) turned my bed so that I could see the tower lit up in orange. I've never had school spirit or pride in any organization whatsoever, but for some reason I cried. For some reason I loved the sight of the tower at that moment. I've recovered completely. I was angry for a while and spent a lot of time screaming and damning anyone who could walk while I made my way around in a wheelchair. I marveled at the fact that, even when I was on crutches, nice families at the Arboretum would still pull their children closer and hold their purses tighter. I began to keep a journal, but by the time I had written five entries my anger was gone. My depression was gone. I couldn't even dwell of death, which I know I had cheated. I was just glad to be alive and to put it all behind me. Now I'm physically and emotionally recovered. I don't have nightmares and I don't fear cars. I don't know why. Maybe I'll learn that this semester. For some reason I recovered very nicely in all aspects from this whole awful little episode.  The good thing is that I'm happy and sober now. I had attempted suicide twice this past year, once just two weeks before the accident. Then I was put in a situation where I didn't try and death actually came for me, and I fought to stay alive. That's always struck me as odd. Oh well. For whatever reason I am a happier, if quieter person. Things are good. I'm looking forward to psychological experiments this year. Now I'm off. I've written for about thirty minutes and I think it's time for a cigarette. Bye bye now.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-d53474ff64f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_NEUfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I wanted to write about something traumatic that happened to me because, apparently, traumatic experiences and how to deal with them is a pretty big fandango in this class. Something just happened, though, so I want to write about that and see where it takes me in the next nineteen minutes or so. The computer assistant in the theatre department (where I am right now, being a theatre major and all) just complimented me on my hat, a black fedora I bought in Greenwich Village about a year and a half ago. I was visiting for about a week over spring break and auditioning for the elusive Experimental Theatre wing of NYU's Tisch School of the Arts. After a fairly successful audition I concentrated all of my efforts of exploring, something I had done about seven or eight months earlier the first time I visited. This time I was alone, though. The time before I had my brother, eighteen months my junior and my closest friend, at my side and all was well. This time I had to w2ait a couple of days for his arrival, since he couldn't get off school and I could, being a senior and having a few excused absence \"\u001b[0m\u001b[0;34m\"college days\"\u001b[0m\u001b[0;34m\" on my hands. So I set out to explore and found a bar in the mob district of Little Italy that didn't ID and I found myself drunkenly wandering the streets of New York, stumbling upon Strawberry Fields in a haze and not realizing the significance until about a week later. After ...\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-86918592f4f8>\u001b[0m in \u001b[0;36mextract_NEUfeatures\u001b[0;34m(text, min_len)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mNEUActivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-81f120918317>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mzcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpooled2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconved\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-81f120918317>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mzcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpooled2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconved\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    206\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    207\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 208\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.58 GiB (GPU 0; 15.90 GiB total capacity; 13.52 GiB already allocated; 1.41 GiB free; 13.80 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUrBt9Xt_awB",
        "colab_type": "code",
        "outputId": "aeb58c84-b16b-4312-cf7a-e2703d7a68fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "extract_NEUfeatures(\"4. 57 checking in don't know where to start. I do this a lot though kind of relieves stress like candles and music and flowers haha really girly, huh? oh well, I guess that's me more like a girl on the inside. outside is just comfortable. god, my hair is annoying. it's hot as hell, too thick curly hair doesn't go well with the texas heat I'm writing and all I'm thinking is that if you really do read this, how exactly am I being judged man, this could be an essay about me and my identity and how I interpret myself but that wouldn't let you decide for yourself. and I'm way into that. I want to decide. it can be good, bad, whatever haha it's funny when it's a bad decision, but always an experience my Japan far east competition in volleyball bad time to get caught volleyball captain, a lot of responsibilities damn, I miss volleyball but I don't know if I could survive it definitely something fun to do, but no. rotc takes way too much time hahaha only 24 hours. I remember Korea shoot I didn't even know what it was to sleep unless I was riding in a bus getting somewhere awww away trips those rocked memories. friends. love. trust. heartache. god, I miss Korea. I can't believe I talked to Keith and marry I miss them a lot this college thing is really cool, but dang, nothing compares to serious friendship. I miss my baby damn the fact that he's way younger. it doesn't' matter. I'm tired of everyone's \"\"idea\"\" of what is right for me. I loved him for that I can always be myself. whatever that is we'll see. I wonder if I'm going to \"\"find myself\"\" here haha this is the place for it, right? ~~bisexuality~~ I mean it's college and all I'm supposed to understand life and myself and who I am and what I'm like this seems more like an email I would send to phillip we were always like this like reading each other's diary in an email. I wonder what he's up to there are a lot of people like that some that I wouldn't mind forgetting about but why? they all touched me in some way haha that sounds sexual I can't believe I admitted to mars before tat or seo or anyone I didn't think I could talk to her like that it takes a lot of guts on both sides for us to have what we have I love her for that I know she feels guilty. we'll see hopefully this will be a lifelong friendship I'm so lucky for that and I thank god for it not like most people: only talk to him when they need something it's funny how religion works it's only prominent in people's lives when they are in need of something then again, I guess that's how a lot of things work I am learning, though not the innocent, little, trusting girl I used to be or at least, not as much haha Korea taught me that I owe my life to that place more the people than the actual place, I guess. more seo than anything I love him I should feel guilty I should actually be censoring my thoughts right about now but, I guess that wouldn't be the assignment. I love ben. I love seo and I would die if I didn't have both of them in my life selfish? I don't know isn't everybody in some way? I think as long as all the people involved accept and are comfortable and happy. happiness is so important. it's funny when people are happy. I don't have to be happy but I couldn't live with myself otherwise so many things play on happiness love. trust. comfort dang, I think I said that before this is something I would send to Mr. clausen I hope his father is okay I would know how hard it would be for him if he wasn't damn. CSM I hope you're watching over me and I know I do some pretty messed up things stuff you wouldn't expect from me but, it's the truth I guess that's a good thing knowing me for who I am maybe it's not all good ben would die if he knew the entire truth can I live with myself knowing I cheated him???? I don't know air force honor code \"\"I will not lie, steal or cheat or tolerate among us anyone who does\"\". do I absolutely have to live with that? isn't it, after all, my decision who will know, right? but, no. I couldn't do that the only thing is ben right now my only source of guilt then again, also my soul source of happiness and love and passion and pleasure I hope all that won't turn into regret and pain. god, after rod, I don't know if I can handle that I don't know I would become another American girl I am so not that or at least, I would argue that I'm not whatever. I don't even remember when I started I don't think I'm supposed to be thinking about that maybe this is all wrong. maybe I'm supposed to be doing this word association thing cloud. picnic. ben. love. good thing. sex. passion. seo. lifelong friend, lover, everything I want and need. kind of like my mom except not I don't know should it be words or sentences I think that I think in phrases it's actually harder writing one word at a time whatever. damn, I need a cigarette shit, but I promised 7 today I think I passed that a few hours ago damn smoker's alley. haha is that what it's called. hahaha I feel so unamerican. mars told me I would be hahaha. it's all good: the allAmerican blond ass Keith feels isolated. I'm still okay. it's a good thing. I don't know for how long I'm scared shitless that I'm going to get cancer or something not because I'm going to die shoot, I could care less. I'm happy. I can dies happy. I will die happy. it's just because my mom would die I remember telling her. you know she cried I've never seen her cry only when it somehow deals with me. damn, she loves me god, that is the greatest thing of all knowing that your heart is in the teeth of your creation wow sounds like a JEWEL song I should listen to her very inspiring kind of like talking to people who are passionate about what they do. damn, I love that maybe that's why I'm big into guys who sing and write poetry it's funny, because ben doesn't do either one, and I am so in love with this guy. shit, I don't even want kids, and I would have them for him he knows that I hope it'll last. I figure this is the hardest part. me in college him still in hS I really don't want to deny him a high school social life he's sweet about it I don't know I don't want him to think in years from now \"\"what if\"\". you know??? god, I hope not. but I make him happy and he makes me happy and we complete each other hahaa same thing with seo god, this is weird. james doesn't think it'll last. a triangle with me as the main point I don't know shoot, I'm special enough, right? who says I can't have it all that sounds conceited. but I'm not. not if you really got to know me anyway confident? I don't know. more uncertain and scared. reminds me of my identity poem: TYPICAL ECCENTRICITY. whoa it's 5. 20\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-96b6a96f8d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_NEUfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4. 57 checking in don't know where to start. I do this a lot though kind of relieves stress like candles and music and flowers haha really girly, huh? oh well, I guess that's me more like a girl on the inside. outside is just comfortable. god, my hair is annoying. it's hot as hell, too thick curly hair doesn't go well with the texas heat I'm writing and all I'm thinking is that if you really do read this, how exactly am I being judged man, this could be an essay about me and my identity and how I interpret myself but that wouldn't let you decide for yourself. and I'm way into that. I want to decide. it can be good, bad, whatever haha it's funny when it's a bad decision, but always an experience my Japan far east competition in volleyball bad time to get caught volleyball captain, a lot of responsibilities damn, I miss volleyball but I don't know if I could survive it definitely something fun to do, but no. rotc takes way too much time hahaha only 24 hours. I remember Korea shoot I didn't even know what it was to sleep unless I was riding in a bus getting somewhere awww away trips those rocked memories. friends. love. trust. heartache. god, I miss Korea. I can't believe I talked to Keith and marry I miss them a lot this college thing is really cool, but dang, nothing compares to serious friendship. I miss my baby damn the fact that he's way younger. it doesn't' matter. I'm tired of everyone's \"\u001b[0m\u001b[0;34m\"...\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-86918592f4f8>\u001b[0m in \u001b[0;36mextract_NEUfeatures\u001b[0;34m(text, min_len)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mNEUActivation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-81f120918317>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mzcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.83 GiB (GPU 0; 15.90 GiB total capacity; 13.53 GiB already allocated; 1.41 GiB free; 13.80 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ongq36WPD8p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_NEUfeatures(\"help\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtWQbwmxlPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import punkt\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVFFwxuhxusl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}